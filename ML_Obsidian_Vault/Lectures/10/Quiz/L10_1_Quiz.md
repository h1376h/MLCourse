# Lecture 10.1: Foundations of Model Evaluation Quiz

## Overview
This quiz contains 5 questions covering different topics from section 10.1 of the lectures on Foundations of Model Evaluation, including evaluation concepts, generalization, overfitting/underfitting, bias-variance tradeoff, and evaluation process.

## Question 1

### Problem Statement
Consider the following training and test performance metrics:

| Model | Training Accuracy | Test Accuracy | Training Loss | Test Loss |
|-------|------------------|---------------|---------------|-----------|
| A     | 0.95             | 0.92          | 0.12          | 0.18      |
| B     | 0.98             | 0.85          | 0.05          | 0.32      |
| C     | 0.75             | 0.74          | 0.45          | 0.48      |

#### Task
1. [🔍] Which model shows signs of overfitting?
2. [🔍] Which model shows signs of underfitting?
3. [🔍] Which model has the best generalization?
4. [🔍] What is the generalization gap for each model?

For a detailed explanation of this question, see [Question 1: Training vs Test Performance Analysis](L10_1_1_explanation.md).

## Question 2

### Problem Statement
Generalization is the ability of a model to perform well on unseen data.

#### Task
1. [📚] What is the difference between training and test performance?
2. [📚] Why is generalization important in machine learning?
3. [📚] What is the relationship between model complexity and generalization?
4. [📚] How do you measure generalization in practice?

For a detailed explanation of this question, see [Question 2: Generalization Concepts](L10_1_2_explanation.md).

## Question 3

### Problem Statement
Overfitting and underfitting are common problems in machine learning.

#### Task
1. [📚] What is overfitting and how do you recognize it?
2. [📚] What is underfitting and how do you recognize it?
3. [📚] What causes overfitting in machine learning models?
4. [📚] What causes underfitting in machine learning models?

For a detailed explanation of this question, see [Question 3: Overfitting and Underfitting](L10_1_3_explanation.md).

## Question 4

### Problem Statement
The bias-variance tradeoff is a fundamental concept in machine learning.

#### Task
1. [📚] What is bias in the context of machine learning?
2. [📚] What is variance in the context of machine learning?
3. [📚] How does model complexity affect bias and variance?
4. [📚] What is the optimal point in the bias-variance tradeoff?

For a detailed explanation of this question, see [Question 4: Bias-Variance Tradeoff](L10_1_4_explanation.md).

## Question 5

### Problem Statement
Model evaluation follows a systematic process.

#### Task
1. [📚] What are the main steps in the model evaluation process?
2. [📚] How do you choose appropriate evaluation metrics?
3. [📚] What is the role of cross-validation in evaluation?
4. [📚] How do you ensure evaluation results are reliable?

For a detailed explanation of this question, see [Question 5: Model Evaluation Process](L10_1_5_explanation.md).
