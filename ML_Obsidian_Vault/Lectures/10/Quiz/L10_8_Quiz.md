# Lecture 10.8: Advanced Evaluation Topics Quiz

## Overview
This quiz contains 5 questions covering different topics from section 10.8 of the lectures on Advanced Evaluation Topics, including statistical significance, model comparison, statistical tests, multiple comparison problem, and evaluation best practices.

## Question 1

### Problem Statement
Statistical significance testing helps determine if performance differences are real.

#### Task
1. [🔍] What is a null hypothesis in model comparison?
2. [🔍] What is a p-value and how do you interpret it?
3. [🔍] What is the significance level and how do you choose it?
4. [🔍] What is the difference between statistical and practical significance?

For a detailed explanation of this question, see [Question 1: Statistical Significance Basics](L10_8_1_explanation.md).

## Question 2

### Problem Statement
Comparing multiple models requires appropriate statistical tests.

#### Task
1. [📚] When would you use a t-test for model comparison?
2. [📚] When would you use ANOVA for model comparison?
3. [📚] When would you use the Wilcoxon signed-rank test?
4. [📚] How do you choose between parametric and non-parametric tests?

For a detailed explanation of this question, see [Question 2: Statistical Tests for Model Comparison](L10_8_2_explanation.md).

## Question 3

### Problem Statement
The multiple comparison problem occurs when testing many hypotheses.

#### Task
1. [📚] What is the multiple comparison problem?
2. [📚] What is the Bonferroni correction and how does it work?
3. [📚] What is the false discovery rate (FDR) approach?
4. [📚] How do you balance statistical power with multiple testing?

For a detailed explanation of this question, see [Question 3: Multiple Comparison Problem](L10_8_3_explanation.md).

## Question 4

### Problem Statement
Evaluation bias can lead to misleading conclusions about model performance.

#### Task
1. [📚] What is data leakage and how does it affect evaluation?
2. [📚] What is selection bias in model evaluation?
3. [📚] What is temporal bias and how do you avoid it?
4. [📚] How do you ensure evaluation results are reproducible?

For a detailed explanation of this question, see [Question 4: Evaluation Bias and Pitfalls](L10_8_4_explanation.md).

## Question 5

### Problem Statement
Best practices help ensure reliable and meaningful model evaluation.

#### Task
1. [📚] **Practice 1**: How do you choose appropriate evaluation metrics?
2. [📚] **Practice 2**: How do you ensure proper data splitting?
3. [📚] **Practice 3**: How do you report evaluation results?
4. [📚] **Practice 4**: How do you validate evaluation conclusions?

For each practice, explain the key principles and implementation considerations.

For a detailed explanation of this question, see [Question 5: Evaluation Best Practices](L10_8_5_explanation.md).
