# Lecture 7.1: Foundations of Ensemble Learning Quiz

## Overview
This quiz contains 5 questions covering different topics from section 7.1 of the lectures on Foundations of Ensemble Learning, including ensemble concepts, types of ensembles, diversity importance, and combination strategies.

## Question 1

### Problem Statement
Consider three individual models that make predictions on the same test set:

| Model | Accuracy |
|-------|----------|
| A     | 75%      |
| B     | 78%      |
| C     | 72%      |

#### Task
1. [ğŸ”] What is the average accuracy of the individual models?
2. [ğŸ”] If you use simple majority voting, what is the minimum accuracy the ensemble could achieve?
3. [ğŸ”] What is the maximum accuracy the ensemble could achieve?
4. [ğŸ”] Explain why an ensemble might perform better than the average of individual models

For a detailed explanation of this question, see [Question 1: Ensemble Performance Analysis](L7_1_1_explanation.md).

## Question 2

### Problem Statement
Ensemble learning combines multiple base learners to improve performance.

#### Task
1. [ğŸ“š] Name the three main types of ensemble methods
2. [ğŸ“š] What is the key principle behind ensemble learning?
3. [ğŸ“š] Why is diversity among base learners important?
4. [ğŸ“š] Give an example of when ensemble learning might not help

For a detailed explanation of this question, see [Question 2: Ensemble Learning Principles](L7_1_2_explanation.md).

## Question 3

### Problem Statement
Consider an ensemble with 5 base models that use different combination strategies.

#### Task
1. [ğŸ”] If using simple averaging, what weight does each model have?
2. [ğŸ”] If using weighted averaging with weights $[0.3, 0.2, 0.2, 0.15, 0.15]$, what is the sum of weights?
3. [ğŸ”] What is the advantage of weighted averaging over simple averaging?
4. [ğŸ”] When might simple averaging be preferred over weighted averaging?

For a detailed explanation of this question, see [Question 3: Ensemble Combination Strategies](L7_1_3_explanation.md).

## Question 4

### Problem Statement
Ensemble diversity is crucial for good performance.

#### Task
1. [ğŸ“š] What are three ways to create diversity among base learners?
2. [ğŸ“š] Why is too much diversity a problem?
3. [ğŸ“š] What is the relationship between diversity and ensemble size?
4. [ğŸ“š] How can you measure diversity in an ensemble?

For a detailed explanation of this question, see [Question 4: Ensemble Diversity](L7_1_4_explanation.md).

## Question 5

### Problem Statement
Ensemble learning has both advantages and challenges.

#### Task
1. [ğŸ“š] **Advantage 1**: How does ensemble learning improve generalization?
2. [ğŸ“š] **Advantage 2**: How does ensemble learning reduce overfitting?
3. [ğŸ“š] **Challenge 1**: What are the computational costs of ensembles?
4. [ğŸ“š] **Challenge 2**: How do ensembles affect model interpretability?

For a detailed explanation of this question, see [Question 5: Ensemble Advantages and Challenges](L7_1_5_explanation.md).
